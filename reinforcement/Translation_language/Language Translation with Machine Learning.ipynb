{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Language Translation with Machine Learning"
      ],
      "metadata": {
        "id": "uEpM958KeZhA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o5MFtNEk2INf"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing\n",
        "\n",
        "import os\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import re\n",
        "\n",
        "import seaborn as sns\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Input, LSTM, Embedding, Dense\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dataset in google colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "FsgmVgUK2Yny",
        "outputId": "eb72d777-2ce4-4c6f-de0f-8ffe04c94f2d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fca2007e-182f-4e2c-a9a0-828ee7bb3392\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fca2007e-182f-4e2c-a9a0-828ee7bb3392\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Hindi_English_Truncated_Corpus.csv to Hindi_English_Truncated_Corpus.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines=pd.read_csv(\"Hindi_English_Truncated_Corpus.csv\",encoding='utf-8')\n",
        "print(lines.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI_g1Bl3_1Ok",
        "outputId": "d91af095-e64f-4242-a46d-7b8820e549cc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      source                                   english_sentence  \\\n",
            "0        ted  politicians do not have permission to do what ...   \n",
            "1        ted         I'd like to tell you about one such child,   \n",
            "2  indic2012  This percentage is even greater than the perce...   \n",
            "3        ted  what we really mean is that they're bad at not...   \n",
            "4  indic2012  .The ending portion of these Vedas is called U...   \n",
            "\n",
            "                                      hindi_sentence  \n",
            "0  राजनीतिज्ञों के पास जो कार्य करना चाहिए, वह कर...  \n",
            "1  मई आपको ऐसे ही एक बच्चे के बारे में बताना चाहू...  \n",
            "2   यह प्रतिशत भारत में हिन्दुओं प्रतिशत से अधिक है।  \n",
            "3     हम ये नहीं कहना चाहते कि वो ध्यान नहीं दे पाते  \n",
            "4        इन्हीं वेदों का अंतिम भाग उपनिषद कहलाता है।  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines=lines[lines['source']=='ted']\n",
        "lines=lines[~pd.isnull(lines['english_sentence'])]\n",
        "lines.drop_duplicates(inplace=True)\n",
        "# Let us pick any 25000 rows from the dataset\n",
        "lines=lines.sample(n=25000,random_state=42)\n",
        "lines.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvn--xUC_46R",
        "outputId": "f3284b92-598f-4d40-ee3c-97a5be4c6067"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.lower())\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "f85DWOt-AOOv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\"'\", '', x))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\"'\", '', x))"
      ],
      "metadata": {
        "id": "H7Xi9KAGAScn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "# Remove all the special characters\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
      ],
      "metadata": {
        "id": "a9XSaQF3AWcl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_digits = str.maketrans('', '', digits)\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.translate(remove_digits))\n",
        "\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x: re.sub(\"[२३०८१५७९४६]\", \"\", x))\n",
        "\n",
        "# Remove extra spaces\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: x.strip())\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: x.strip())\n",
        "lines['english_sentence']=lines['english_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "lines['hindi_sentence']=lines['hindi_sentence'].apply(lambda x: re.sub(\" +\", \" \", x))\n",
        "\n",
        "lines['hindi_sentence'] = lines['hindi_sentence'].apply(lambda x : 'START_ '+ x + ' _END')"
      ],
      "metadata": {
        "id": "qOExERLUAa-E"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Get English and Hindi Vocabulary\n",
        "all_eng_words=set()\n",
        "for eng in lines['english_sentence']:\n",
        "    for word in eng.split():\n",
        "        if word not in all_eng_words:\n",
        "            all_eng_words.add(word)\n",
        "\n",
        "all_hindi_words=set()\n",
        "for hin in lines['hindi_sentence']:\n",
        "    for word in hin.split():\n",
        "        if word not in all_hindi_words:\n",
        "            all_hindi_words.add(word)\n",
        "lines['length_eng_sentence']=lines['english_sentence'].apply(lambda x:len(x.split(\" \")))\n",
        "lines['length_hin_sentence']=lines['hindi_sentence'].apply(lambda x:len(x.split(\" \")))"
      ],
      "metadata": {
        "id": "1xLZyp_sAe-U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines=lines[lines['length_eng_sentence']<=20]\n",
        "lines=lines[lines['length_hin_sentence']<=20]\n",
        "max_length_src=max(lines['length_hin_sentence'])\n",
        "max_length_tar=max(lines['length_eng_sentence'])\n",
        "\n",
        "input_words = sorted(list(all_eng_words))\n",
        "target_words = sorted(list(all_hindi_words))\n",
        "num_encoder_tokens = len(all_eng_words)\n",
        "num_decoder_tokens = len(all_hindi_words)\n",
        "num_encoder_tokens, num_decoder_tokens\n",
        "\n",
        "num_decoder_tokens += 1 #for zero padding\n",
        "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n",
        "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])\n",
        "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())\n",
        "lines = shuffle(lines)"
      ],
      "metadata": {
        "id": "rXVZMSgLAivE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Model to Translate English to Hindi"
      ],
      "metadata": {
        "id": "7PG-FqUaAnBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = lines['english_sentence'], lines['hindi_sentence']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2,random_state=42)\n",
        "\n",
        "X_train.to_pickle('X_train.pkl')\n",
        "X_test.to_pickle('X_test.pkl')"
      ],
      "metadata": {
        "id": "AwxnLjb0Anfg"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text.split()):\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text.split()):\n",
        "                    if t<len(target_text.split())-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)\n",
        "          \n",
        "latent_dim=300\n",
        "encoder_inputs = Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "model.summary()\n",
        "\n",
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 100\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbW1-cKQAsHP",
        "outputId": "3fb11119-7c6c-434b-8e2a-2895c1822c9a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 300)    4209000     ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 300)    5262300     ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 300),        721200      ['embedding[0][0]']              \n",
            "                                 (None, 300),                                                     \n",
            "                                 (None, 300)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 300),  721200      ['embedding_1[0][0]',            \n",
            "                                 (None, 300),                     'lstm[0][1]',                   \n",
            "                                 (None, 300)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 17541)  5279841     ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 16,193,541\n",
            "Trainable params: 16,193,541\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size)\n",
        "\n",
        "model.save_weights('nmt_weights.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MgVmSqYBqy8",
        "outputId": "d50f7bc8-e0ef-44e2-91e7-dbcb665fe4f0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-f8d89dc252d7>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "154/154 [==============================] - 78s 418ms/step - loss: 6.9390 - val_loss: 6.3596\n",
            "Epoch 2/100\n",
            "154/154 [==============================] - 50s 323ms/step - loss: 6.3118 - val_loss: 6.3150\n",
            "Epoch 3/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 6.2647 - val_loss: 6.2967\n",
            "Epoch 4/100\n",
            "154/154 [==============================] - 50s 322ms/step - loss: 6.2190 - val_loss: 6.2385\n",
            "Epoch 5/100\n",
            "154/154 [==============================] - 50s 323ms/step - loss: 6.1389 - val_loss: 6.1555\n",
            "Epoch 6/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 6.0510 - val_loss: 6.0839\n",
            "Epoch 7/100\n",
            "154/154 [==============================] - 49s 321ms/step - loss: 5.9631 - val_loss: 6.0069\n",
            "Epoch 8/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 5.8812 - val_loss: 5.9496\n",
            "Epoch 9/100\n",
            "154/154 [==============================] - 49s 320ms/step - loss: 5.8114 - val_loss: 5.8952\n",
            "Epoch 10/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 5.7434 - val_loss: 5.8480\n",
            "Epoch 11/100\n",
            "154/154 [==============================] - 50s 322ms/step - loss: 5.6823 - val_loss: 5.8121\n",
            "Epoch 12/100\n",
            "154/154 [==============================] - 50s 328ms/step - loss: 5.6238 - val_loss: 5.7703\n",
            "Epoch 13/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 5.5704 - val_loss: 5.7275\n",
            "Epoch 14/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 5.5183 - val_loss: 5.6986\n",
            "Epoch 15/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 5.4690 - val_loss: 5.6702\n",
            "Epoch 16/100\n",
            "154/154 [==============================] - 50s 322ms/step - loss: 5.4220 - val_loss: 5.6412\n",
            "Epoch 17/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 5.3774 - val_loss: 5.6119\n",
            "Epoch 18/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 5.3324 - val_loss: 5.5900\n",
            "Epoch 19/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 5.2891 - val_loss: 5.5724\n",
            "Epoch 20/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 5.2488 - val_loss: 5.5450\n",
            "Epoch 21/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 5.2076 - val_loss: 5.5219\n",
            "Epoch 22/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 5.1700 - val_loss: 5.5003\n",
            "Epoch 23/100\n",
            "154/154 [==============================] - 50s 323ms/step - loss: 5.1321 - val_loss: 5.4842\n",
            "Epoch 24/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 5.0952 - val_loss: 5.4782\n",
            "Epoch 25/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 5.0586 - val_loss: 5.4533\n",
            "Epoch 26/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 5.0250 - val_loss: 5.4359\n",
            "Epoch 27/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 4.9885 - val_loss: 5.4277\n",
            "Epoch 28/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 4.9542 - val_loss: 5.4116\n",
            "Epoch 29/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.9191 - val_loss: 5.3996\n",
            "Epoch 30/100\n",
            "154/154 [==============================] - 49s 321ms/step - loss: 4.8864 - val_loss: 5.3893\n",
            "Epoch 31/100\n",
            "154/154 [==============================] - 51s 334ms/step - loss: 4.8519 - val_loss: 5.3796\n",
            "Epoch 32/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 4.8168 - val_loss: 5.3646\n",
            "Epoch 33/100\n",
            "154/154 [==============================] - 50s 323ms/step - loss: 4.7810 - val_loss: 5.3479\n",
            "Epoch 34/100\n",
            "154/154 [==============================] - 51s 332ms/step - loss: 4.7502 - val_loss: 5.3370\n",
            "Epoch 35/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.7159 - val_loss: 5.3474\n",
            "Epoch 36/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 4.6833 - val_loss: 5.3293\n",
            "Epoch 37/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 4.6508 - val_loss: 5.3239\n",
            "Epoch 38/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 4.6157 - val_loss: 5.3134\n",
            "Epoch 39/100\n",
            "154/154 [==============================] - 49s 321ms/step - loss: 4.5830 - val_loss: 5.3066\n",
            "Epoch 40/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 4.5505 - val_loss: 5.2900\n",
            "Epoch 41/100\n",
            "154/154 [==============================] - 51s 333ms/step - loss: 4.5167 - val_loss: 5.2809\n",
            "Epoch 42/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 4.4834 - val_loss: 5.2765\n",
            "Epoch 43/100\n",
            "154/154 [==============================] - 50s 328ms/step - loss: 4.4493 - val_loss: 5.2679\n",
            "Epoch 44/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 4.4170 - val_loss: 5.2675\n",
            "Epoch 45/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 4.3851 - val_loss: 5.2597\n",
            "Epoch 46/100\n",
            "154/154 [==============================] - 49s 320ms/step - loss: 4.3522 - val_loss: 5.2504\n",
            "Epoch 47/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.3217 - val_loss: 5.2498\n",
            "Epoch 48/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 4.2871 - val_loss: 5.2441\n",
            "Epoch 49/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 4.2552 - val_loss: 5.2479\n",
            "Epoch 50/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.2246 - val_loss: 5.2613\n",
            "Epoch 51/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 4.1924 - val_loss: 5.2440\n",
            "Epoch 52/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 4.1611 - val_loss: 5.2476\n",
            "Epoch 53/100\n",
            "154/154 [==============================] - 49s 320ms/step - loss: 4.1290 - val_loss: 5.2472\n",
            "Epoch 54/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.1005 - val_loss: 5.2357\n",
            "Epoch 55/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 4.0680 - val_loss: 5.2436\n",
            "Epoch 56/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 4.0376 - val_loss: 5.2378\n",
            "Epoch 57/100\n",
            "154/154 [==============================] - 50s 328ms/step - loss: 4.0065 - val_loss: 5.2364\n",
            "Epoch 58/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 3.9761 - val_loss: 5.2382\n",
            "Epoch 59/100\n",
            "154/154 [==============================] - 50s 328ms/step - loss: 3.9461 - val_loss: 5.2418\n",
            "Epoch 60/100\n",
            "154/154 [==============================] - 51s 330ms/step - loss: 3.9169 - val_loss: 5.2518\n",
            "Epoch 61/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 3.8856 - val_loss: 5.2446\n",
            "Epoch 62/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 3.8554 - val_loss: 5.2468\n",
            "Epoch 63/100\n",
            "154/154 [==============================] - 49s 321ms/step - loss: 3.8256 - val_loss: 5.2517\n",
            "Epoch 64/100\n",
            "154/154 [==============================] - 51s 335ms/step - loss: 3.7948 - val_loss: 5.2739\n",
            "Epoch 65/100\n",
            "154/154 [==============================] - 51s 333ms/step - loss: 3.7672 - val_loss: 5.2638\n",
            "Epoch 66/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 3.7355 - val_loss: 5.2642\n",
            "Epoch 67/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 3.7076 - val_loss: 5.2723\n",
            "Epoch 68/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 3.6775 - val_loss: 5.2714\n",
            "Epoch 69/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 3.6478 - val_loss: 5.2845\n",
            "Epoch 70/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 3.6193 - val_loss: 5.2836\n",
            "Epoch 71/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 3.5895 - val_loss: 5.2902\n",
            "Epoch 72/100\n",
            "154/154 [==============================] - 51s 335ms/step - loss: 3.5619 - val_loss: 5.3004\n",
            "Epoch 73/100\n",
            "154/154 [==============================] - 49s 322ms/step - loss: 3.5295 - val_loss: 5.3023\n",
            "Epoch 74/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 3.5015 - val_loss: 5.3185\n",
            "Epoch 75/100\n",
            "154/154 [==============================] - 51s 332ms/step - loss: 3.4728 - val_loss: 5.3215\n",
            "Epoch 76/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 3.4429 - val_loss: 5.3203\n",
            "Epoch 77/100\n",
            "154/154 [==============================] - 50s 323ms/step - loss: 3.4131 - val_loss: 5.3405\n",
            "Epoch 78/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 3.3862 - val_loss: 5.3518\n",
            "Epoch 79/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 3.3569 - val_loss: 5.3503\n",
            "Epoch 80/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 3.3285 - val_loss: 5.3549\n",
            "Epoch 81/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 3.2982 - val_loss: 5.3642\n",
            "Epoch 82/100\n",
            "154/154 [==============================] - 51s 333ms/step - loss: 3.2706 - val_loss: 5.3729\n",
            "Epoch 83/100\n",
            "154/154 [==============================] - 50s 326ms/step - loss: 3.2409 - val_loss: 5.3743\n",
            "Epoch 84/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 3.2126 - val_loss: 5.3862\n",
            "Epoch 85/100\n",
            "154/154 [==============================] - 51s 333ms/step - loss: 3.1833 - val_loss: 5.3985\n",
            "Epoch 86/100\n",
            "154/154 [==============================] - 50s 325ms/step - loss: 3.1552 - val_loss: 5.4085\n",
            "Epoch 87/100\n",
            "154/154 [==============================] - 51s 329ms/step - loss: 3.1273 - val_loss: 5.4307\n",
            "Epoch 88/100\n",
            "154/154 [==============================] - 50s 322ms/step - loss: 3.0983 - val_loss: 5.4270\n",
            "Epoch 89/100\n",
            "154/154 [==============================] - 51s 334ms/step - loss: 3.0697 - val_loss: 5.4604\n",
            "Epoch 90/100\n",
            "154/154 [==============================] - 51s 333ms/step - loss: 3.0400 - val_loss: 5.4508\n",
            "Epoch 91/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 3.0112 - val_loss: 5.4622\n",
            "Epoch 92/100\n",
            "154/154 [==============================] - 50s 323ms/step - loss: 2.9848 - val_loss: 5.4851\n",
            "Epoch 93/100\n",
            "154/154 [==============================] - 51s 333ms/step - loss: 2.9555 - val_loss: 5.4824\n",
            "Epoch 94/100\n",
            "154/154 [==============================] - 51s 332ms/step - loss: 2.9276 - val_loss: 5.4966\n",
            "Epoch 95/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 2.8982 - val_loss: 5.4973\n",
            "Epoch 96/100\n",
            "154/154 [==============================] - 51s 331ms/step - loss: 2.8698 - val_loss: 5.4975\n",
            "Epoch 97/100\n",
            "154/154 [==============================] - 50s 324ms/step - loss: 2.8411 - val_loss: 5.5238\n",
            "Epoch 98/100\n",
            "154/154 [==============================] - 51s 333ms/step - loss: 2.8117 - val_loss: 5.5371\n",
            "Epoch 99/100\n",
            "154/154 [==============================] - 50s 327ms/step - loss: 2.7836 - val_loss: 5.5423\n",
            "Epoch 100/100\n",
            "154/154 [==============================] - 51s 332ms/step - loss: 2.7570 - val_loss: 5.5551\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the input sequence to get the \"thought vectors\"\n",
        "encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "\n",
        "dec_emb2= dec_emb_layer(decoder_inputs) # Get the embeddings of the decoder sequence\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h2, state_c2]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) # A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "    [decoder_inputs] + decoder_states_inputs,\n",
        "    [decoder_outputs2] + decoder_states2)\n",
        "    \n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0] = target_token_index['START_']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += ' '+sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if (sampled_char == '_END' or\n",
        "           len(decoded_sentence) > 50):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "train_gen = generate_batch(X_train, y_train, batch_size = 1)\n",
        "k=-1"
      ],
      "metadata": {
        "id": "L--vbS09eErg"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k+=1\n",
        "(input_seq, actual_output), _ = next(train_gen)\n",
        "decoded_sentence = decode_sequence(input_seq)\n",
        "print('Input English sentence:', X_train[k:k+1].values[0])\n",
        "print('Actual Hindi Translation:', y_train[k:k+1].values[0][6:-4])\n",
        "print('Predicted Hindi Translation:', decoded_sentence[:-4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LAnQAh2eNUX",
        "outputId": "1d12ead1-dd7d-4f47-ab0e-da206717aad9"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Input English sentence: and were not adequately addressing more bigger problems\n",
            "Actual Hindi Translation:  और लिहाज़ा हम समस्या को उसकी विशालता के अनुरूप हल नहीं कर रहे थे । \n",
            "Predicted Hindi Translation:  और हम अभी भी पानी को इस्तेमाल कर रहे थे \n"
          ]
        }
      ]
    }
  ]
}